{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thoongee/TextAnalysis/blob/main/coupang_crawling_0428.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvoXcilqZuXW",
        "outputId": "a509957d-5f07-4cd8-f93d-20d2fac61e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1270 sha256=cc219bfd5123c15f932995e8de8586eda0d2dfe73fba089477a370c45cdcc2a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl\n",
        "!pip install requests\n",
        "!pip install bs4\n",
        "!pip install lxml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "from pathlib import Path\n",
        "from typing import Optional,Union,Dict,List\n",
        "from openpyxl import Workbook\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import requests as rq\n",
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "import requests, openpyxl"
      ],
      "metadata": {
        "id": "aFD3VHDcZ2QN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6Qe_uBZcygH",
        "outputId": "70036c95-9e77-4252-a816-e6fcf67dd241"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_headers(\n",
        "    key: str,\n",
        "    default_value: Optional[str] = None\n",
        "    )-> Dict[str,Dict[str,str]]:\n",
        "    \"\"\" Get Headers \"\"\"\n",
        "    JSON_FILE : str = '/content/drive/MyDrive/텍스트분석2023/headers.json'\n",
        "\n",
        "    with open(JSON_FILE,'r',encoding='UTF-8') as file:\n",
        "        headers : Dict[str,Dict[str,str]] = json.loads(file.read())\n",
        "\n",
        "    try :\n",
        "        return headers[key]\n",
        "    except:\n",
        "        if default_value:\n",
        "            return default_value\n",
        "        raise EnvironmentError(f'Set the {key}')\n",
        "\n",
        "class Coupang:\n",
        "    @staticmethod\n",
        "    def get_product_code(url: str)-> str:\n",
        "        \"\"\" 입력받은 URL 주소의 PRODUCT CODE 추출하는 메소드 \"\"\"\n",
        "        prod_code : str = url.split('products/')[-1].split('?')[0]\n",
        "        return prod_code\n",
        "\n",
        "    def __init__(self)-> None:\n",
        "        self.__headers : Dict[str,str] = get_headers(key='headers')\n",
        "        self.page = 1\n",
        "        self.star5 = 0\n",
        "        self.star3 = 0\n",
        "        self.star1 = 0\n",
        "\n",
        "    ## review_url 파라미터 추가\n",
        "    def main(self,review_url)-> List[List[Dict[str,Union[str,int]]]]:\n",
        "        # URL 주소\n",
        "        URL : str = self.input_review_url(review_url)\n",
        "\n",
        "        # URL의 Product Code 추출\n",
        "        prod_code : str = self.get_product_code(url=URL)\n",
        "\n",
        "        url = [f'https://www.coupang.com/vp/product/reviews?productId={prod_code}&page=1&size=5&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=3&ratingSummary=true']\n",
        "        self.__headers['referer'] = URL\n",
        "        with rq.Session() as session:\n",
        "            with session.get(url=url[0],headers=self.__headers) as response :\n",
        "                html = response.text\n",
        "                soup = bs(html,'html.parser')\n",
        "                test = soup.select(\"div.js_reviewArticleHiddenValue\")\n",
        "                total_review = 0\n",
        "                for i in range(len(test)):\n",
        "                    total_review += int(test[i].attrs['data-count'])\n",
        "                total_page = int(np.ceil(total_review/5))\n",
        "                print(\"(이야야야야ㅏㅇ) \", total_review, int(np.ceil(total_review/5)))\n",
        "\n",
        "        # URL 주소 재가공\n",
        "        URLS : List[str] = [f'https://www.coupang.com/vp/product/reviews?productId={prod_code}&page={page}&size=5&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=3&ratingSummary=true' for page in range(1,self.input_page_count() + 1)]\n",
        "\n",
        "        # __headers에 referer 키 추가\n",
        "        self.__headers['referer'] = URL\n",
        "\n",
        "        with rq.Session() as session:\n",
        "            return [self.fetch(url=url,session=session) for url in URLS]\n",
        "\n",
        "    def fetch(self,url:str,session)-> List[Dict[str,Union[str,int]]]:\n",
        "        \n",
        "        save_data : List[Dict[str,Union[str,int]]] = list()\n",
        "\n",
        "        with session.get(url=url,headers=self.__headers) as response :\n",
        "            html = response.text\n",
        "            soup = bs(html,'html.parser')\n",
        "\n",
        "            # Article Boxes\n",
        "            article_lenth = len(soup.select('article.sdp-review__article__list'))\n",
        "\n",
        "            for idx in range(article_lenth):\n",
        "                dict_data : Dict[str,Union[str,int]] = dict()\n",
        "                articles = soup.select('article.sdp-review__article__list')\n",
        "\n",
        "                review_content = articles[idx].select_one('div.sdp-review__article__list__review > div')\n",
        "                if review_content == None:\n",
        "                    # review_content = '등록된 리뷰내용이 없습니다'\n",
        "                    continue\n",
        "                else:\n",
        "                    review_content = re.sub('[\\n\\t]','',review_content.text.strip())\n",
        "\n",
        "                rating = articles[idx].select_one('div.sdp-review__article__list__info__product-info__star-orange')\n",
        "                # print(\"(3) \", rating)\n",
        "                if int(rating.attrs['data-rating']) == 1:\n",
        "                    if self.star1 >= 50:\n",
        "                        continue\n",
        "                    elif self.star1 < 50:\n",
        "                        rating, user_name, prod_name, headline, help_cnt = self.sub(articles, idx, 1)\n",
        "                        self.star1 += 1\n",
        "                elif int(rating.attrs['data-rating']) == 3:\n",
        "                    if self.star3 >= 50:\n",
        "                        continue\n",
        "                    elif self.star3 < 50:\n",
        "                        rating, user_name, prod_name, headline, help_cnt = self.sub(articles, idx, 3)\n",
        "                        self.star3 += 1\n",
        "                elif int(rating.attrs['data-rating']) == 5:\n",
        "                    if self.star5 >= 50:\n",
        "                        continue\n",
        "                    elif self.star5 < 50:\n",
        "                        rating, user_name, prod_name, headline, help_cnt = self.sub(articles, idx, 5)\n",
        "                        self.star5 += 1\n",
        "                else:\n",
        "                    continue\n",
        "               \n",
        "\n",
        "                # 구매자 이름\n",
        "                user_name = articles[idx].select_one('span.sdp-review__article__list__info__user__name')\n",
        "                if user_name == None or user_name.text == '':\n",
        "                    user_name = '-'\n",
        "                else:\n",
        "                    user_name = user_name.text.strip()\n",
        "\n",
        "                # 평점\n",
        "                rating = articles[idx].select_one('div.sdp-review__article__list__info__product-info__star-orange')\n",
        "                if rating == None:\n",
        "                    rating = 0\n",
        "                else :\n",
        "                    rating = int(rating.attrs['data-rating'])\n",
        "\n",
        "                # 구매자 상품명\n",
        "                prod_name = articles[idx].select_one('div.sdp-review__article__list__info__product-info__name')\n",
        "                if prod_name == None or prod_name.text == '':\n",
        "                    prod_name = '-'\n",
        "                else:\n",
        "                    prod_name = prod_name.text.strip()\n",
        "\n",
        "                # 헤드라인(타이틀)\n",
        "                headline = articles[idx].select_one('div.sdp-review__article__list__headline')\n",
        "                if headline == None or headline.text == '':\n",
        "                    headline = '등록된 헤드라인이 없습니다'\n",
        "                else:\n",
        "                    headline = headline.text.strip()\n",
        "\n",
        "                # 리뷰 내용\n",
        "                review_content = articles[idx].select_one('div.sdp-review__article__list__review > div')\n",
        "                if review_content == None :\n",
        "                    review_content = '등록된 리뷰내용이 없습니다'\n",
        "                else:\n",
        "                    review_content = re.sub('[\\n\\t]','',review_content.text.strip())\n",
        "\n",
        "                # 맛 만족도\n",
        "                answer = articles[idx].select_one('span.sdp-review__article__list__survey__row__answer')\n",
        "                if answer == None or answer.text == '':\n",
        "                    answer = '맛 평가 없음'\n",
        "                else:\n",
        "                    answer = answer.text.strip()\n",
        "\n",
        "                dict_data['prod_name'] = prod_name\n",
        "                dict_data['user_name'] = user_name\n",
        "                dict_data['rating'] = rating\n",
        "                dict_data['headline'] = headline\n",
        "                dict_data['review_content'] = review_content\n",
        "                dict_data['answer'] = answer\n",
        "\n",
        "                save_data.append(dict_data)\n",
        "\n",
        "                print(dict_data , '\\n')\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "            return save_data\n",
        "    def sub(self, articles, idx, rat):\n",
        "        # print()\n",
        "        # if star_count >= 50:\n",
        "        #     return \"x\", \"x\", \"x\", \"x\", \"x\"\n",
        "        # else:\n",
        "        rating = rat\n",
        "\n",
        "        # 구매자 이름\n",
        "        user_name = articles[idx].select_one('span.sdp-review__article__list__info__user__name')\n",
        "        if user_name == None or user_name.text == '':\n",
        "            user_name = '-'\n",
        "        else:\n",
        "            user_name = user_name.text.strip()\n",
        "\n",
        "        # 평점\n",
        "        # rating = articles[idx].select_one('div.sdp-review__article__list__info__product-info__star-orange')\n",
        "        # if rating == None:\n",
        "        #     rating = 0\n",
        "        # else :\n",
        "        #     rating = int(rating.attrs['data-rating'])\n",
        "\n",
        "        # 구매자 상품명\n",
        "        prod_name = articles[idx].select_one('div.sdp-review__article__list__info__product-info__name')\n",
        "        if prod_name == None or prod_name.text == '':\n",
        "            prod_name = '-'\n",
        "        else:\n",
        "            prod_name = prod_name.text.strip()\n",
        "\n",
        "        # 헤드라인(타이틀)\n",
        "        headline = articles[idx].select_one('div.sdp-review__article__list__headline')\n",
        "        if headline == None or headline.text == '':\n",
        "            headline = '등록된 헤드라인이 없습니다'\n",
        "        else:\n",
        "            headline = headline.text.strip()\n",
        "\n",
        "        # 리뷰 내용\n",
        "        # review_content = articles[idx].select_one('div.sdp-review__article__list__review > div')\n",
        "        # if review_content == None :\n",
        "        #     review_content = '등록된 리뷰내용이 없습니다'\n",
        "        # else:\n",
        "        #     review_content = re.sub('[\\n\\t]','',review_content.text.strip())\n",
        "\n",
        "        # 도움횟수\n",
        "        help_cnt = articles[idx].select_one('div.sdp-review__article__list__help.js_reviewArticleHelpfulContainer')\n",
        "        if help_cnt == None:\n",
        "            help_cnt = 0\n",
        "        else:\n",
        "            help_cnt = int(help_cnt.attrs['data-count'])\n",
        "\n",
        "        return rating, user_name, prod_name, headline, help_cnt\n",
        "\n",
        "    def input_review_url(self,review_url)-> str:\n",
        "        while True:\n",
        "            # Window\n",
        "            os.system('cls')\n",
        "            \n",
        "            # Review URL\n",
        "#             review_url : str = input('원하시는 상품의 URL 주소를 입력해주세요\\n\\nEx)\\nhttps://www.coupang.com/vp/products/6451503812?itemId=14007944553&vendorItemId=73528488680&sourceType=srp_product_ads&clickEventId=28aaab30-71e3-4f30-9059-07a29eb1b27f&korePlacement=15&koreSubPlacement=6&q=%EB%9E%A9%EB%85%B8%EC%89%AC&itemsCount=36&searchId=af6bda06076947a39f847ed86a718c34&rank=5&isAddedCart=\\n\\n:')\n",
        "            if not review_url :\n",
        "                # Window\n",
        "                os.system('cls')\n",
        "                # Mac\n",
        "                #os.system('clear')\n",
        "                print('URL 주소가 입력되지 않았습니다')\n",
        "                continue\n",
        "            return review_url\n",
        "\n",
        "    def input_page_count(self)-> int:\n",
        "        # Window\n",
        "        os.system('cls')\n",
        "        # Mac\n",
        "        #os.system('clear')\n",
        "        while True:\n",
        "            page_count : str = input('페이지 수를 입력하세요\\n\\n:')\n",
        "            if not page_count:\n",
        "                print('페이지 수가 입력되지 않았습니다\\n')\n",
        "                continue\n",
        "\n",
        "            return int(page_count)\n",
        "\n",
        "class OpenPyXL:\n",
        "    @staticmethod\n",
        "    def save_file(review_url)-> None:\n",
        "        # 크롤링 결과\n",
        "        results : List[List[Dict[str,Union[str,int]]]] = Coupang().main(review_url)\n",
        "\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.append(['상품명','구매자 이름','구매자 평점','리뷰 제목','리뷰 내용','도움횟수'])\n",
        "\n",
        "        row = 2\n",
        "\n",
        "        for x in results:\n",
        "            for result in x :\n",
        "                ws[f'A{row}'] = result['prod_name']\n",
        "                ws[f'B{row}'] = result['user_name']\n",
        "                ws[f'C{row}'] = result['rating']\n",
        "                ws[f'D{row}'] = result['headline']\n",
        "                ws[f'E{row}'] = result['review_content']\n",
        "                ws[f'F{row}'] = result['answer']\n",
        "\n",
        "                row += 1\n",
        "        ## 저장경로는 수정할 것\n",
        "        savePath : str = os.path.abspath('C:\\\\Users\\\\cjina\\\\OneDrive - 서울과학기술대학교\\\\대학원\\\\수업\\\\텍스트분석\\\\팀플\\\\data')\n",
        "        fileName : str = results[0][0]['prod_name'] + '.xlsx'\n",
        "\n",
        "        if not os.path.exists(savePath):\n",
        "            os.mkdir(savePath)\n",
        "\n",
        "        wb.save(os.path.join(savePath,fileName))\n",
        "        wb.close()\n",
        "        print(f'파일 저장완료!\\n\\n{os.path.join(savePath,fileName)}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cG7JCrk-Z4hT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Evinue():\n",
        "  #url = page url\n",
        "    headers = {\n",
        "        'Referer': 'https://www.google.com/',\n",
        "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "        'accept-encoding': 'gzip, deflate, br',\n",
        "        'accept-language': 'ko,th;q=0.9,en-US;q=0.8,en;q=0.7,ru;q=0.6,ko-KR;q=0.5,la;q=0.4',\n",
        "        'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36\"\n",
        "    }\n",
        "    link_list = []\n",
        "    page_num = 1\n",
        "    while(True):\n",
        "      ## 쿠팡 스킨케어 링크\n",
        "      url = f'https://www.coupang.com/np/categories/176530?listSize=60&brand=&offerCondition=&filterType=top_brand&isPriceRange=false&minPrice=&maxPrice=&page={page_num}&channel=user&fromComponent=N&selectedPlpKeepFilter=&sorter=saleCountDesc&filter=&component=176430&rating=0'\n",
        "      page_num += 1\n",
        "      res = requests.get(url, headers = headers, verify=False)\n",
        "      res.raise_for_status()\n",
        "      soup = bs(res.text, \"lxml\")\n",
        "\n",
        "      items = soup.find_all(\"li\", attrs={\"class\":re.compile(\"^baby-product\")})\n",
        "      \n",
        "      for item in items:\n",
        "          link = item.find(\"a\", attrs={\"class\":\"baby-product-link\"})[\"href\"]\n",
        "          p_link = 'https://www.coupang.com'+link+'&isAddedCart='\n",
        "          link_list.append(p_link)\n",
        "          print(len(link_list))\n",
        "          ## 총 크롤링 할 상품 개수 200개\n",
        "          if len(link_list) == 10:\n",
        "            return link_list\n",
        "\n",
        "def NoEvinue():\n",
        "    \n",
        "    headers = {\n",
        "        'Referer': 'https://www.google.com/',\n",
        "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "        'accept-encoding': 'gzip, deflate, br',\n",
        "        'accept-language': 'ko,th;q=0.9,en-US;q=0.8,en;q=0.7,ru;q=0.6,ko-KR;q=0.5,la;q=0.4',\n",
        "        'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    link_list = []\n",
        "    page_num = 1\n",
        "    while(True):\n",
        "      ## 쿠팡 스킨케어 링크\n",
        "      url= f'https://www.coupang.com/np/categories/176530?listSize=60&brand=&offerCondition=&filterType=top_brand&isPriceRange=false&minPrice=&maxPrice=&page={page_num}&channel=user&fromComponent=N&selectedPlpKeepFilter=&sorter=saleCountDesc&filter=&component=176430&rating=0'\n",
        "      page_num += 1\n",
        "      res = requests.get(url, headers = headers, verify=False)\n",
        "      res.raise_for_status()\n",
        "      soup = bs(res.text, \"lxml\")\n",
        "      \n",
        "      items = soup.find_all(\"li\", attrs={\"class\":re.compile(\"^baby-product\")})\n",
        "      \n",
        "      for item in items:\n",
        "          badge = item.find(\"img\", attrs={\"class\":\"badge-ico\"})\n",
        "          if badge:\n",
        "              continue\n",
        "          else:\n",
        "              link = item.find(\"a\", attrs={\"class\":\"baby-product-link\"})[\"href\"]\n",
        "              p_link = 'https://www.coupang.com'+link+'&isAddedCart='\n",
        "              link_list.append(p_link)   \n",
        "          ## 크롤링할 상품 개수 총 200개\n",
        "          if len(link_list) == 200:\n",
        "            break\n",
        "\n",
        "    return link_list"
      ],
      "metadata": {
        "id": "HP9KTtLMZ_Qo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = Evinue()\n",
        "for url in urls:\n",
        "    OpenPyXL.save_file(url)"
      ],
      "metadata": {
        "id": "LufQ4C8EfRF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9b175e-5ccc-4c4a-df74-0cf3ff25a1b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.coupang.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "(이야야야야ㅏㅇ)  19200 3840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = NoEvinue()\n",
        "for url in urls:\n",
        "    OpenPyXL.save_file(url)"
      ],
      "metadata": {
        "id": "xH8sTDheg6y1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}